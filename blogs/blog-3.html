<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building a Scalable Movie Recommendation System - Praveen Kumar</title>
    
    <!-- SEO Meta Tags -->
    <meta name="description" content="Deep dive into building a production-ready movie recommendation system using TF-IDF, SVD, and content-based filtering. Learn to scale from 10K to 1M+ movies with Django and advanced ML.">
    <meta name="keywords" content="Recommendation System, Machine Learning, TF-IDF, SVD, Content-Based Filtering, Django, Scalable ML, Movie Recommendation">
    <meta name="author" content="Praveen Kumar">
    
    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="Building a Scalable Movie Recommendation System">
    <meta property="og:description" content="From 10K to 1M+ movies: A complete guide to building production-ready recommendation systems using advanced ML, TF-IDF, SVD, and Django.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://inboxpraveen.github.io/blogs/blog-3.html">
    <meta property="og:image" content="https://inboxpraveen.github.io/blogs/resources/blog-3/Header.png">
    <meta property="og:image:alt" content="Movie Recommendation System Architecture">
    <meta property="og:site_name" content="Praveen Kumar Portfolio">
    <meta property="article:published_time" content="2025-12-05">
    <meta property="article:author" content="Praveen Kumar">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="Recommendation Systems">
    <meta property="article:tag" content="Django">
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Building a Scalable Movie Recommendation System">
    <meta name="twitter:description" content="Production-ready recommendation system handling 1M+ movies. Learn TF-IDF, SVD, content-based filtering, and Django deployment.">
    <meta name="twitter:image" content="https://inboxpraveen.github.io/blogs/resources/blog-3/Header.png">
    <meta name="twitter:image:alt" content="Movie Recommendation System">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://inboxpraveen.github.io/blogs/blog-3.html">
    
    <link rel="icon" type="image/x-icon" href="../assests/favicon.ico">
    <link rel="stylesheet" href="../index.css">
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="nav-container">
            <div class="logo" onclick="window.location.href='../index.html'" style="cursor: pointer;">PK</div>
            <ul class="nav-links" id="navLinks">
                <li><a href="../index.html">Home</a></li>
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../index.html#blog">Blog</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
                <li><a href="../assests/Resume.pdf" target="_blank" title="Updated Nov 2025">Resume</a></li>
            </ul>
            <button class="mobile-menu" id="mobileMenu">‚ò∞</button>
        </div>
    </nav>

    <!-- Blog Post Page - Movie Recommendation System -->
    <div class="page-container active">
        <div class="page-header">
            <div class="container">
                <a href="../index.html#blog" class="back-button">‚Üê Back to Blog</a>
                <h1 class="page-title">Building a Scalable Movie Recommendation System</h1>
                <div class="page-meta">
                    <div class="meta-item">
                        <span>üìÖ</span>
                        <span>Published: December 5, 2025</span>
                    </div>
                    <div class="meta-item">
                        <span>‚è±Ô∏è</span>
                        <span>16 min read</span>
                    </div>
                    <div class="meta-item">
                        <span>üè∑Ô∏è</span>
                        <span>Machine Learning ‚Ä¢ Recommendation Systems</span>
                    </div>
                    <div class="meta-item">
                        <span>üëÅÔ∏è</span>
                        <span>1,247 views</span>
                    </div>
                </div>
            </div>
        </div>

        <div class="blog-content-area">
            <div style="text-align: center; margin: 2rem 0;">
                <img src="resources/blog-3/Header.png" alt="Movie Recommendation System Header" style="max-width: 100%; height: auto; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);">
            </div>
            
            <p>
                Recommendation systems are everywhere‚ÄîNetflix suggests your next binge-worthy series, Spotify curates 
                your perfect playlist, and Amazon knows what you want before you do. But how do these systems actually 
                work under the hood? More importantly, how do you build one that scales from a few thousand items to 
                <em>millions</em> without breaking a sweat?
            </p>

            <p>
                In this deep dive, I'll walk you through building a <strong>production-ready movie recommendation 
                system</strong> that evolved from handling 10,000 movies to successfully processing <strong>930,000+ 
                movies</strong> from the TMDB dataset. We'll cover the machine learning techniques, architectural 
                decisions, optimization strategies, and Django deployment‚Äîeverything you need to build a real-world 
                recommendation engine.
            </p>

            <h2>Why Movie Recommendations Are Hard</h2>
            <p>
                At first glance, recommending movies seems straightforward: <em>"Find movies similar to this one."</em> 
                But the devil is in the details:
            </p>

            <ul>
                <li><strong>Scale:</strong> Computing similarity across millions of movie pairs is computationally expensive</li>
                <li><strong>Quality vs. Coverage:</strong> Should you recommend obscure gems or stick to popular hits?</li>
                <li><strong>Cold Start:</strong> How do you recommend without user history or ratings?</li>
                <li><strong>Context Understanding:</strong> "Science Fiction" isn't the same as "Sci-Fi Action Thriller"</li>
                <li><strong>Performance:</strong> Users expect recommendations in milliseconds, not seconds</li>
            </ul>

            <p>
                The system I built addresses all of these challenges using <strong>content-based filtering</strong> with 
                advanced feature engineering and dimensionality reduction.
            </p>

            <h2>The Evolution: From 10K to 930K+ Movies</h2>
            <p>
                The journey started with the classic MovieLens dataset (around 10,000 movies). While educational, it 
                wasn't representative of real-world scale. I then upgraded to the <strong>TMDB Movies Dataset 2023</strong> 
                with 1.3M+ entries‚Äîa game changer.
            </p>

            <div class="table-container">
                <table class="content-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Original (MovieLens)</th>
                            <th>Upgraded (TMDB)</th>
                            <th>Improvement</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Dataset Size</td>
                            <td>10K movies</td>
                            <td>930K+ movies</td>
                            <td>93x larger</td>
                        </tr>
                        <tr>
                            <td>Data Files</td>
                            <td>7 CSVs (complex merge)</td>
                            <td>1 CSV (unified)</td>
                            <td>Simplified pipeline</td>
                        </tr>
                        <tr>
                            <td>Memory Usage</td>
                            <td>800MB (10K)</td>
                            <td>350MB (100K)</td>
                            <td>56% reduction</td>
                        </tr>
                        <tr>
                            <td>Training Time</td>
                            <td>5 min (10K)</td>
                            <td>15 min (100K)</td>
                            <td>Optimized</td>
                        </tr>
                        <tr>
                            <td>Model Size</td>
                            <td>320MB</td>
                            <td>180MB</td>
                            <td>44% smaller</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h2>The Architecture: How It Actually Works</h2>
            
            <div style="text-align: center; margin: 2rem 0;">
                <img src="resources/blog-3/Architecture.png" alt="Recommendation System Architecture" style="max-width: 100%; height: auto; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);">
            </div>

            <h3>The Recommendation Pipeline</h3>
            <p>
                The system works in seven distinct stages:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Recommendation Pipeline Stages</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code>1. User Input ‚Üí "Inception"
2. Fuzzy Matching ‚Üí Find closest title in database
3. Get Movie Index ‚Üí title_to_idx["Inception"] = 42
4. Fetch Similarity Scores ‚Üí similarity_matrix[42] = [0.95, 0.87, 0.82, ...]
5. Sort & Filter ‚Üí Top 15 movies by similarity
6. Apply Business Rules ‚Üí Min rating, year range, genre filters
7. Return Results ‚Üí With metadata, posters, IMDb links</code></pre>
            </div>

            <h2>Feature Engineering: The Secret Sauce</h2>
            <p>
                The quality of recommendations depends heavily on what features you use. I engineered a comprehensive 
                feature set that captures multiple aspects of a movie:
            </p>

            <h3>Original Features (MovieLens)</h3>
            <ul>
                <li>Cast (top 3 actors)</li>
                <li>Director</li>
                <li>Genres</li>
                <li>Keywords</li>
            </ul>

            <h3>Enhanced Features (TMDB Upgrade)</h3>
            <ul>
                <li><strong>Production Companies</strong> (weighted by prominence)</li>
                <li><strong>Production Countries</strong></li>
                <li><strong>Plot Overview</strong> (first 50 words, stemmed)</li>
                <li><strong>Taglines</strong> (marketing keywords)</li>
                <li><strong>Quality Score</strong> (vote_average √ó log(vote_count + 1))</li>
                <li><strong>Poster URLs</strong> and <strong>IMDb IDs</strong> for rich display</li>
            </ul>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Feature Engineering Pipeline</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">def</span> <span class="function">engineer_features</span>(df):
    <span class="comment"># Parse JSON columns for genres, keywords, companies</span>
    df[<span class="string">'genres'</span>] = df[<span class="string">'genres'</span>].apply(<span class="keyword">lambda</span> x: parse_json_column(x, <span class="string">'name'</span>))
    df[<span class="string">'keywords'</span>] = df[<span class="string">'keywords'</span>].apply(<span class="keyword">lambda</span> x: parse_json_column(x, <span class="string">'name'</span>))
    df[<span class="string">'companies'</span>] = df[<span class="string">'production_companies'</span>].apply(<span class="keyword">lambda</span> x: parse_json_column(x, <span class="string">'name'</span>))
    
    <span class="comment"># Clean and stem keywords (remove spaces, lowercase)</span>
    df[<span class="string">'keywords'</span>] = df[<span class="string">'keywords'</span>].apply(
        <span class="keyword">lambda</span> x: [stemmer.stem(kw.lower().replace(<span class="string">" "</span>, <span class="string">""</span>)) <span class="keyword">for</span> kw <span class="keyword">in</span> x[:15]]
    )
    
    <span class="comment"># Weight genres and primary production company more heavily</span>
    df[<span class="string">'genres_weighted'</span>] = df[<span class="string">'genres'</span>].apply(<span class="keyword">lambda</span> x: x * <span class="number">2</span>)
    df[<span class="string">'company_weighted'</span>] = df[<span class="string">'companies'</span>].apply(
        <span class="keyword">lambda</span> x: [x[<span class="number">0</span>].lower().replace(<span class="string">" "</span>, <span class="string">""</span>)] * <span class="number">2</span> <span class="keyword">if</span> x <span class="keyword">else</span> []
    )
    
    <span class="comment"># Extract overview words (first 50, cleaned)</span>
    df[<span class="string">'overview_words'</span>] = df[<span class="string">'overview'</span>].fillna(<span class="string">''</span>).apply(
        <span class="keyword">lambda</span> x: [w.lower() <span class="keyword">for</span> w <span class="keyword">in</span> x.split()[:50]]
    )
    
    <span class="comment"># Create comprehensive "soup" of all features</span>
    df[<span class="string">'soup'</span>] = (
        df[<span class="string">'keywords'</span>] + 
        df[<span class="string">'genres_weighted'</span>] + 
        df[<span class="string">'company_weighted'</span>] +
        df[<span class="string">'companies'</span>] +
        df[<span class="string">'countries'</span>] +
        df[<span class="string">'overview_words'</span>] +
        df[<span class="string">'tagline_words'</span>]
    )
    
    df[<span class="string">'soup'</span>] = df[<span class="string">'soup'</span>].apply(<span class="keyword">lambda</span> x: <span class="string">' '</span>.join(x))
    
    <span class="keyword">return</span> df</code></pre>
            </div>

            <h2>The ML Core: TF-IDF + SVD</h2>
            <p>
                The recommendation engine uses a two-stage approach:
            </p>

            <h3>Stage 1: TF-IDF Vectorization</h3>
            <p>
                <strong>TF-IDF</strong> (Term Frequency-Inverse Document Frequency) converts movie features into 
                numerical vectors. It assigns higher weights to distinctive terms and lower weights to common ones.
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - TF-IDF Matrix Construction</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer

<span class="comment"># Configure TF-IDF based on dataset size</span>
n_movies = len(df)
max_features = <span class="number">20000</span> <span class="keyword">if</span> n_movies > <span class="number">100000</span> <span class="keyword">else</span> <span class="number">15000</span>

tfidf = TfidfVectorizer(
    analyzer=<span class="string">'word'</span>,
    ngram_range=(<span class="number">1</span>, <span class="number">2</span>),       <span class="comment"># Unigrams + bigrams</span>
    min_df=<span class="number">3</span>,                   <span class="comment"># Must appear in 3+ docs</span>
    max_df=<span class="number">0.7</span>,                 <span class="comment"># Ignore if in >70% of docs</span>
    stop_words=<span class="string">'english'</span>,
    max_features=max_features,
    sublinear_tf=<span class="keyword">True</span>          <span class="comment"># Use log scaling</span>
)

tfidf_matrix = tfidf.fit_transform(df[<span class="string">'soup'</span>])
<span class="keyword">print</span>(<span class="string">f"TF-IDF matrix shape: {tfidf_matrix.shape}"</span>)
<span class="comment"># Output: (100000, 20000) - 100K movies √ó 20K features</span></code></pre>
            </div>

            <h3>Stage 2: SVD Dimensionality Reduction</h3>
            <p>
                A 100K √ó 20K matrix is huge (2 billion elements!). <strong>SVD</strong> (Singular Value Decomposition) 
                compresses this into a much smaller space while preserving the most important patterns.
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - SVD Compression</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> TruncatedSVD

<span class="comment"># Reduce from 20K features to 500 latent dimensions</span>
svd = TruncatedSVD(n_components=<span class="number">500</span>, random_state=<span class="number">42</span>)
reduced_matrix = svd.fit_transform(tfidf_matrix)

explained_var = svd.explained_variance_ratio_.sum()
<span class="keyword">print</span>(<span class="string">f"Explained variance: {explained_var:.3f}"</span>)
<span class="comment"># Output: 0.847 - We kept 84.7% of the information!</span>

<span class="keyword">print</span>(<span class="string">f"Reduced matrix shape: {reduced_matrix.shape}"</span>)
<span class="comment"># Output: (100000, 500) - 97.5% smaller!</span></code></pre>
            </div>

            <h3>Stage 3: Cosine Similarity</h3>
            <p>
                Finally, we compute how similar each movie is to every other movie using cosine similarity:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Similarity Computation</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity

<span class="comment"># For very large datasets, compute in chunks</span>
<span class="keyword">if</span> reduced_matrix.shape[<span class="number">0</span>] > <span class="number">50000</span>:
    similarity_matrix = compute_similarity_in_chunks(reduced_matrix)
<span class="keyword">else</span>:
    similarity_matrix = cosine_similarity(reduced_matrix)

<span class="comment"># Result: 100K √ó 100K matrix of similarity scores</span>
<span class="comment"># similarity_matrix[i][j] = how similar movie i is to movie j</span></code></pre>
            </div>

            <h2>Quality Filtering: Not All Movies Are Equal</h2>
            <p>
                One major upgrade was adding <strong>quality thresholds</strong>. The TMDB dataset includes everything 
                from Oscar winners to obscure indie films with 2 votes. I implemented three quality tiers:
            </p>

            <div class="table-container">
                <table class="content-table">
                    <thead>
                        <tr>
                            <th>Threshold</th>
                            <th>Min Votes</th>
                            <th>Movies</th>
                            <th>Use Case</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Low</td>
                            <td>5+</td>
                            <td>~930K</td>
                            <td>Maximum coverage</td>
                        </tr>
                        <tr>
                            <td>Medium ‚≠ê</td>
                            <td>50+</td>
                            <td>~200K</td>
                            <td>Balanced (recommended)</td>
                        </tr>
                        <tr>
                            <td>High</td>
                            <td>500+</td>
                            <td>~50K</td>
                            <td>Highest quality only</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <p>
                I also compute a <strong>quality score</strong> that balances rating and vote count:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Quality Score</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="comment"># Prevent high-rated movies with few votes from dominating</span>
df[<span class="string">'quality_score'</span>] = df[<span class="string">'vote_average'</span>] * np.log1p(df[<span class="string">'vote_count'</span>])

<span class="comment"># Sort by quality and take top N</span>
df = df.sort_values(<span class="string">'quality_score'</span>, ascending=<span class="keyword">False</span>)</code></pre>
            </div>

            <h2>Django Integration: From Model to Web App</h2>
            <p>
                Training the model is only half the battle. I built a complete Django web application for deployment:
            </p>

            <div style="text-align: center; margin: 2rem 0;">
                <img src="resources/blog-3/Application-Demo.gif" alt="Application Demo" style="max-width: 100%; height: auto; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);">
            </div>

            <h3>Model Loading with Background Threading</h3>
            <p>
                Loading a 180MB model on every request is terrible for performance. I implemented singleton pattern 
                with background loading:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Django Model Singleton</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">import</span> threading
<span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> pandas <span class="keyword">as</span> pd
<span class="keyword">from</span> scipy.sparse <span class="keyword">import</span> load_npz

_RECOMMENDER = <span class="keyword">None</span>
_MODEL_LOADING = <span class="keyword">False</span>

<span class="keyword">def</span> <span class="function">_load_model_in_background</span>():
    <span class="keyword">global</span> _RECOMMENDER, _MODEL_LOADING
    
    _MODEL_LOADING = <span class="keyword">True</span>
    model_dir = settings.MODEL_DIR
    
    <span class="keyword">try</span>:
        <span class="comment"># Load metadata (movie info)</span>
        metadata = pd.read_parquet(model_dir / <span class="string">'movie_metadata.parquet'</span>)
        
        <span class="comment"># Load similarity matrix (sparse format for efficiency)</span>
        similarity_matrix = load_npz(model_dir / <span class="string">'similarity_matrix.npz'</span>).toarray()
        
        <span class="comment"># Load title mappings</span>
        <span class="keyword">with</span> open(model_dir / <span class="string">'title_to_idx.json'</span>) <span class="keyword">as</span> f:
            title_to_idx = json.load(f)
        
        _RECOMMENDER = MovieRecommender(metadata, similarity_matrix, title_to_idx)
        _MODEL_LOADING = <span class="keyword">False</span>
        logger.info(<span class="string">"Model loaded successfully"</span>)
        
    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:
        logger.error(<span class="string">f"Failed to load model: {e}"</span>)
        _MODEL_LOADING = <span class="keyword">False</span>

<span class="comment"># Start loading on app startup</span>
threading.Thread(target=_load_model_in_background, daemon=<span class="keyword">True</span>).start()</code></pre>
            </div>

            <h3>Fuzzy Title Matching</h3>
            <p>
                Users don't always type exact titles. I use difflib for fuzzy matching:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Fuzzy Search</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">from</span> difflib <span class="keyword">import</span> get_close_matches

<span class="keyword">def</span> <span class="function">find_movie</span>(title: str) -> str:
    <span class="string">"""Find closest matching title"""</span>
    matches = get_close_matches(
        title, 
        title_to_idx.keys(), 
        n=<span class="number">1</span>, 
        cutoff=<span class="number">0.6</span>  <span class="comment"># 60% similarity threshold</span>
    )
    <span class="keyword">return</span> matches[<span class="number">0</span>] <span class="keyword">if</span> matches <span class="keyword">else</span> <span class="keyword">None</span>

<span class="comment"># Examples:</span>
<span class="comment"># "inceptoin" ‚Üí "Inception"</span>
<span class="comment"># "dark knigth" ‚Üí "The Dark Knight"</span></code></pre>
            </div>

            <h2>Advanced Filtering & Business Logic</h2>
            <p>
                Raw similarity scores aren't always what users want. I added sophisticated filtering:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Advanced Recommendation Filters</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">def</span> <span class="function">get_recommendations</span>(
    movie_title: str,
    n: int = <span class="number">15</span>,
    min_rating: float = <span class="keyword">None</span>,
    min_year: int = <span class="keyword">None</span>,
    max_year: int = <span class="keyword">None</span>,
    genres: List[str] = <span class="keyword">None</span>
):
    <span class="comment"># Find movie and get similarity scores</span>
    matched_title = find_movie(movie_title)
    movie_idx = title_to_idx[matched_title]
    sim_scores = list(enumerate(similarity_matrix[movie_idx]))
    sim_scores = sorted(sim_scores, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="keyword">True</span>)[<span class="number">1</span>:]
    
    recommendations = []
    <span class="keyword">for</span> idx, score <span class="keyword">in</span> sim_scores:
        <span class="keyword">if</span> len(recommendations) >= n:
            <span class="keyword">break</span>
            
        movie = metadata.iloc[idx]
        
        <span class="comment"># Apply filters</span>
        <span class="keyword">if</span> min_rating <span class="keyword">and</span> movie[<span class="string">'vote_average'</span>] < min_rating:
            <span class="keyword">continue</span>
        
        <span class="keyword">if</span> min_year <span class="keyword">and</span> movie[<span class="string">'release_year'</span>] < min_year:
            <span class="keyword">continue</span>
        
        <span class="keyword">if</span> max_year <span class="keyword">and</span> movie[<span class="string">'release_year'</span>] > max_year:
            <span class="keyword">continue</span>
        
        <span class="keyword">if</span> genres <span class="keyword">and not</span> any(g <span class="keyword">in</span> movie[<span class="string">'genres'</span>] <span class="keyword">for</span> g <span class="keyword">in</span> genres):
            <span class="keyword">continue</span>
        
        recommendations.append({
            <span class="string">'title'</span>: movie[<span class="string">'title'</span>],
            <span class="string">'rating'</span>: <span class="string">f"{movie['vote_average']:.1f}/10"</span>,
            <span class="string">'genres'</span>: <span class="string">', '</span>.join(movie[<span class="string">'genres'</span>]),
            <span class="string">'similarity_score'</span>: <span class="string">f"{score:.3f}"</span>,
            <span class="string">'poster_url'</span>: <span class="string">f"https://image.tmdb.org/t/p/w500{movie['poster_path']}"</span>,
            <span class="string">'imdb_link'</span>: <span class="string">f"https://www.imdb.com/title/{movie['imdb_id']}"</span>
        })
    
    <span class="keyword">return</span> recommendations</code></pre>
            </div>

            <h2>Performance Optimizations</h2>
            <p>
                Getting from concept to production required several key optimizations:
            </p>

            <h3>1. Sparse Matrix Storage</h3>
            <p>
                The similarity matrix for 100K movies would be 100K √ó 100K = 10 billion floats (40GB!). 
                Using sparse matrix format (scipy.sparse.csr_matrix) reduces this to ~150MB.
            </p>

            <h3>2. Parquet Instead of CSV</h3>
            <p>
                Parquet is a columnar format that's 3-5x smaller and loads 10x faster than CSV:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Performance Comparison</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="comment"># CSV: 48MB file, 12 seconds to load</span>
df = pd.read_csv(<span class="string">'movie_metadata.csv'</span>)

<span class="comment"># Parquet: 12MB file, 1.2 seconds to load</span>
df = pd.read_parquet(<span class="string">'movie_metadata.parquet'</span>)</code></pre>
            </div>

            <h3>3. Chunked Similarity Computation</h3>
            <p>
                For datasets > 50K movies, computing the full similarity matrix at once can crash. I compute in chunks:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Chunked Processing</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">def</span> <span class="function">compute_similarity_in_chunks</span>(matrix, chunk_size=<span class="number">10000</span>):
    n = matrix.shape[<span class="number">0</span>]
    n_chunks = (n + chunk_size - <span class="number">1</span>) // chunk_size
    
    similarity = np.zeros((n, n), dtype=np.float32)
    
    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_chunks):
        start = i * chunk_size
        end = min((i + <span class="number">1</span>) * chunk_size, n)
        
        chunk_sim = cosine_similarity(matrix[start:end], matrix)
        similarity[start:end, :] = chunk_sim
        
        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:
            <span class="keyword">print</span>(<span class="string">f"Processed {i+1}/{n_chunks} chunks"</span>)
    
    <span class="keyword">return</span> similarity</code></pre>
            </div>

            <h2>Real-World Results</h2>
            <p>
                The final system achieves impressive performance across all metrics:
            </p>

            <div class="table-container">
                <table class="content-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Value</th>
                            <th>Benchmark</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Model Size</td>
                            <td>180MB (100K movies)</td>
                            <td>44% smaller than v1</td>
                        </tr>
                        <tr>
                            <td>Model Load Time</td>
                            <td>3 seconds</td>
                            <td>One-time startup</td>
                        </tr>
                        <tr>
                            <td>Recommendation Time</td>
                            <td>&lt; 50ms</td>
                            <td>Sub-second response</td>
                        </tr>
                        <tr>
                            <td>Memory Usage</td>
                            <td>~200MB (runtime)</td>
                            <td>Efficient caching</td>
                        </tr>
                        <tr>
                            <td>Dataset Size</td>
                            <td>930K+ movies</td>
                            <td>93x larger than original</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h2>Lessons Learned</h2>

            <h3>1. Start with Quality, Not Quantity</h3>
            <p>
                My first attempt used all 1.3M movies‚Äîrecommendations were terrible. Filtering by vote count 
                (quality threshold) dramatically improved relevance.
            </p>

            <h3>2. Feature Engineering > Algorithm Choice</h3>
            <p>
                I spent days tweaking SVD parameters. Then I added production company features and improved 
                recommendations more in one hour than in all that tuning.
            </p>

            <h3>3. User Experience Matters as Much as ML</h3>
            <p>
                Fuzzy matching, poster images, IMDb links, and responsive design made the difference between a 
                "cool demo" and a tool people actually want to use.
            </p>

            <h3>4. Scalability Requires Upfront Design</h3>
            <p>
                The 10K ‚Üí 930K transition would have been impossible without sparse matrices, chunked processing, 
                and efficient data formats from the start.
            </p>

            <h2>What's Next?</h2>
            <p>
                The current system uses content-based filtering. Future enhancements could include:
            </p>

            <ul>
                <li><strong>Collaborative Filtering:</strong> Leverage user rating patterns</li>
                <li><strong>Hybrid Approaches:</strong> Combine content + collaborative + popularity</li>
                <li><strong>Deep Learning:</strong> Neural collaborative filtering with embeddings</li>
                <li><strong>Real-Time Learning:</strong> Update recommendations based on user interactions</li>
                <li><strong>Contextual Recommendations:</strong> Time of day, mood, watching history</li>
            </ul>

            <h2>Try It Yourself</h2>
            <p>
                The complete system is open source and production-ready. You can:
            </p>

            <ul>
                <li>Use the pre-trained model (2K demo movies included)</li>
                <li>Train on the full TMDB dataset (930K+ movies)</li>
                <li>Deploy to Render, Heroku, or AWS in minutes</li>
                <li>Customize features, filters, and UI to your needs</li>
            </ul>

            <blockquote>
                "The best way to understand recommendation systems is to build one yourself. This project gives 
                you production-grade code, comprehensive documentation, and real datasets to learn from."
            </blockquote>

            <div style="margin-top: 3rem; padding: 2rem; background: var(--secondary-bg); border-radius: 15px; border: 1px solid var(--border-color);">
                <h3 style="margin-top: 0;">Resources & Links</h3>
                <ul style="margin-bottom: 2rem;">
                    <li><a href="../projects/project-3.html" style="color: var(--accent-color);">Full Project Page</a></li>
                    <li><a href="https://github.com/inboxpraveen/movie-recommendation-system" style="color: var(--accent-color);" target="_blank">GitHub Repository</a></li>
                    <li><a href="https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies" style="color: var(--accent-color);" target="_blank">TMDB Dataset on Kaggle</a></li>
                    <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" style="color: var(--accent-color);" target="_blank">TF-IDF Documentation</a></li>
                    <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html" style="color: var(--accent-color);" target="_blank">SVD Documentation</a></li>
                </ul>
                
                <h4>Tags:</h4>
                <div style="display: flex; gap: 0.5rem; flex-wrap: wrap; margin-top: 1rem;">
                    <span class="tech-tag">#MachineLearning</span>
                    <span class="tech-tag">#RecommendationSystems</span>
                    <span class="tech-tag">#TF-IDF</span>
                    <span class="tech-tag">#SVD</span>
                    <span class="tech-tag">#Django</span>
                    <span class="tech-tag">#Python</span>
                    <span class="tech-tag">#ContentBasedFiltering</span>
                    <span class="tech-tag">#ScalableML</span>
                </div>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer style="margin-top: 4rem;">
        <div class="container">
            <p>&copy; <span id="copyright-year"></span> Praveen Kumar. Built with passion for AI & open source community.</p>
        </div>
    </footer>

    <script>
        // Mobile menu functionality
        const mobileMenu = document.getElementById('mobileMenu');
        const navLinks = document.getElementById('navLinks');

        mobileMenu.addEventListener('click', () => {
            navLinks.classList.toggle('active');
        });

        // Copy button functionality
        document.addEventListener('click', function(e) {
            if (e.target.classList.contains('copy-button')) {
                const codeBlock = e.target.closest('.code-block');
                const code = codeBlock.querySelector('pre').textContent;
                
                navigator.clipboard.writeText(code).then(() => {
                    e.target.textContent = 'Copied!';
                    setTimeout(() => {
                        e.target.textContent = 'Copy';
                    }, 2000);
                });
            }
        });

        // Navbar background on scroll
        window.addEventListener('scroll', () => {
            const nav = document.querySelector('nav');
            if (window.scrollY > 100) {
                nav.style.background = 'rgba(10, 10, 10, 0.98)';
            } else {
                nav.style.background = 'rgba(10, 10, 10, 0.95)';
            }
        });

        // Update copyright year dynamically
        window.addEventListener('load', function() {
            const yearElement = document.getElementById('copyright-year');
            if (yearElement) {
                yearElement.textContent = new Date().getFullYear();
            }
        });
    </script>
</body>
</html>