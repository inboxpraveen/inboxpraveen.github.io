<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML Algorithms from Scratch - Educational Python Implementation | Praveen Kumar</title>
    
    <!-- SEO Meta Tags -->
    <meta name="description" content="Educational repository implementing 18 fundamental ML algorithms from scratch using Python and NumPy. Features 2,500+ lines of documentation with mathematical foundations and production-quality code.">
    <meta name="keywords" content="Machine Learning from Scratch, ML Algorithms, Python NumPy, Linear Regression, Logistic Regression, Ridge Regression, ML Education, Open Source">
    <meta name="author" content="Praveen Kumar">
    
    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="ML Algorithms from Scratch - Educational Python Implementation">
    <meta property="og:description" content="Educational repository with 18 ML algorithms built from scratch. Complete mathematical foundations, 2,500+ lines of documentation, and production-quality Python code.">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://inboxpraveen.github.io/projects/project-5.html">
    <meta property="og:image" content="https://inboxpraveen.github.io/projects/resources/project-5/Header.png">
    <meta property="og:image:alt" content="ML Algorithms from Scratch">
    <meta property="og:site_name" content="Praveen Kumar Portfolio">
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="ML Algorithms from Scratch - Educational Python Implementation">
    <meta name="twitter:description" content="18 ML algorithms from scratch with NumPy. 2,500+ lines of documentation, mathematical foundations, production code.">
    <meta name="twitter:image" content="https://inboxpraveen.github.io/projects/resources/project-5/Header.png">
    <meta name="twitter:image:alt" content="ML Algorithms from Scratch">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://inboxpraveen.github.io/projects/project-5.html">
    
    <link rel="icon" type="image/x-icon" href="../assests/favicon.ico">
    <link rel="stylesheet" href="../index.css">
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="nav-container">
            <div class="logo" onclick="window.location.href='../index.html'" style="cursor: pointer;">PK</div>
            <ul class="nav-links" id="navLinks">
                <li><a href="../index.html">Home</a></li>
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../index.html#blog">Blog</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
                <li><a href="../assests/Resume.pdf" target="_blank" title="Updated Nov 2025">Resume</a></li>
            </ul>
            <button class="mobile-menu" id="mobileMenu">‚ò∞</button>
        </div>
    </nav>

    <!-- Project Page - ML Algorithms from Scratch -->
    <div class="page-container active">
        <div class="page-header">
            <div class="container">
                <a href="../index.html#projects" class="back-button">‚Üê Back to Projects</a>
                <h1 class="page-title">ML Algorithms from Scratch</h1>
                <div class="page-meta">
                    <div class="meta-item">
                        <span>üìÖ</span>
                        <span>Completed: December 2025</span>
                    </div>
                    <div class="meta-item">
                        <span>‚è±Ô∏è</span>
                        <span>Version: 1.0.0</span>
                    </div>
                    <div class="meta-item">
                        <span>üë•</span>
                        <span>Team Size: Solo</span>
                    </div>
                    <div class="meta-item">
                        <span>üè∑Ô∏è</span>
                        <span>ML Education ‚Ä¢ Python ‚Ä¢ NumPy</span>
                    </div>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2>Project Overview</h2>
            <p>
                <strong>ML Algorithms from Scratch</strong> is a comprehensive educational repository that implements 
                18 fundamental machine learning algorithms using only Python and NumPy. The project demonstrates complete 
                algorithm implementations with mathematical rigor, featuring over <strong>2,500+ lines of documentation</strong> 
                that explain the theory, mathematics, and code behind each algorithm.
            </p>
            
            <div style="text-align: center; margin: 2rem 0;">
                <img src="./resources/project-5/Header.png" alt="ML Algorithms from Scratch" style="max-width: 100%; height: auto; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.3);">
            </div>
            
            <p>
                Unlike typical machine learning tutorials that rely on scikit-learn or TensorFlow, this repository builds 
                every algorithm from first principles. Each implementation follows a consistent object-oriented design 
                pattern with a scikit-learn-like API (<code>fit</code>, <code>predict</code>, <code>score</code>), making 
                it ideal for students, researchers, and engineers who want to understand how ML algorithms actually work 
                under the hood.
            </p>

            <h2>The Challenge</h2>
            <p>
                Understanding machine learning algorithms at a fundamental level presents several key challenges:
            </p>

            <ul>
                <li><strong>Abstract Understanding:</strong> High-level libraries obscure the mathematical operations behind algorithms</li>
                <li><strong>Documentation Gaps:</strong> Most resources either show formulas or code, rarely connecting both thoroughly</li>
                <li><strong>Implementation Complexity:</strong> Building correct, efficient algorithms requires careful design</li>
                <li><strong>Mathematical Rigor:</strong> Balancing mathematical precision with practical, understandable code</li>
                <li><strong>Educational Value:</strong> Creating resources that serve both learning and reference purposes</li>
                <li><strong>Consistency:</strong> Maintaining uniform code patterns across diverse algorithm types</li>
            </ul>

            <h2>Solution Architecture</h2>
            <p>
                The project addresses these challenges through a structured approach combining mathematical foundations 
                with production-quality code:
            </p>

            <div class="table-container">
                <table class="content-table">
                    <thead>
                        <tr>
                            <th>Traditional Learning</th>
                            <th>This Project</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Import library and use</td>
                            <td>Build algorithm from scratch</td>
                        </tr>
                        <tr>
                            <td>Memorize formulas</td>
                            <td>Derive and implement equations</td>
                        </tr>
                        <tr>
                            <td>Trial-and-error tuning</td>
                            <td>Understand parameter effects</td>
                        </tr>
                        <tr>
                            <td>Abstract concepts</td>
                            <td>Concrete code examples</td>
                        </tr>
                        <tr>
                            <td>Limited documentation</td>
                            <td>2,500+ lines of explanations</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h2>Target Audience</h2>
            <p>
                This repository serves multiple user segments in the ML community:
            </p>

            <ul>
                <li><strong>Students & Bootcamp Learners:</strong> Comprehensive resources for understanding ML fundamentals</li>
                <li><strong>Software Engineers:</strong> Clear pathway for transitioning into ML/AI engineering roles</li>
                <li><strong>Interview Candidates:</strong> Complete implementations for technical interview preparation</li>
                <li><strong>Researchers:</strong> Reference implementations for understanding algorithm internals</li>
                <li><strong>Educators:</strong> Teaching materials with detailed explanations and examples</li>
                <li><strong>ML Practitioners:</strong> Deep understanding beyond library usage for better model debugging</li>
            </ul>

            <h2>Technical Specifications</h2>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem; margin: 2rem 0;">
                <div style="background: var(--secondary-bg); padding: 1.5rem; border-radius: 10px; border: 1px solid var(--border-color);">
                    <h3 style="margin-top: 0; color: var(--accent-color);">4 Algorithms</h3>
                    <p>Fully implemented with 14 more planned</p>
                </div>
                <div style="background: var(--secondary-bg); padding: 1.5rem; border-radius: 10px; border: 1px solid var(--border-color);">
                    <h3 style="margin-top: 0; color: var(--accent-color);">2,500+ Lines</h3>
                    <p>Comprehensive documentation across all algorithms</p>
                </div>
                <div style="background: var(--secondary-bg); padding: 1.5rem; border-radius: 10px; border: 1px solid var(--border-color);">
                    <h3 style="margin-top: 0; color: var(--accent-color);">NumPy Only</h3>
                    <p>Pure implementation, no ML libraries used</p>
                </div>
                <div style="background: var(--secondary-bg); padding: 1.5rem; border-radius: 10px; border: 1px solid var(--border-color);">
                    <h3 style="margin-top: 0; color: var(--accent-color);">Interview Ready</h3>
                    <p>Perfect preparation for FAANG interviews</p>
                </div>
            </div>

            <h2>Implementation Status</h2>
            <p>
                The repository currently features <strong>4 completed algorithms</strong> with comprehensive documentation 
                and working code. Development follows a phased approach with 14 additional algorithms planned:
            </p>

            <div class="table-container">
                <table class="content-table">
                    <thead>
                        <tr>
                            <th>#</th>
                            <th>Algorithm</th>
                            <th>Type</th>
                            <th>Code Lines</th>
                            <th>Doc Lines</th>
                            <th>Status</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td><strong>Linear Regression</strong></td>
                            <td>Regression</td>
                            <td>160</td>
                            <td>391</td>
                            <td>‚úÖ Complete</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td><strong>Multiple Regression</strong></td>
                            <td>Regression</td>
                            <td>173</td>
                            <td>356</td>
                            <td>‚úÖ Complete</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td><strong>Ridge Regression</strong></td>
                            <td>Regression</td>
                            <td>256</td>
                            <td>696</td>
                            <td>‚úÖ Complete</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td><strong>Logistic Regression</strong></td>
                            <td>Classification</td>
                            <td>414</td>
                            <td>873</td>
                            <td>‚úÖ Complete</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>Coming Soon</h3>
            <p>The roadmap includes 14 more essential algorithms:</p>
            <ul>
                <li><strong>Classification</strong>: K-Nearest Neighbors, Decision Trees, Naive Bayes, SVM</li>
                <li><strong>Ensemble Methods</strong>: Random Forests, AdaBoost, Gradient Boosting, XGBoost</li>
                <li><strong>Clustering</strong>: k-Means, Hierarchical Clustering</li>
                <li><strong>Dimensionality Reduction</strong>: PCA, t-SNE</li>
                <li><strong>Association Rules</strong>: Apriori Algorithm</li>
            </ul>

            <h2>Core Features</h2>
            
            <h3>1. üìñ Comprehensive Documentation</h3>
            <p>
                Every algorithm includes a detailed markdown file (300-900 lines) that covers:
            </p>
            <ul>
                <li><strong>Intuitive Explanations</strong>: Real-world analogies that make complex concepts relatable</li>
                <li><strong>Mathematical Foundations</strong>: Equations broken down step-by-step with plain language</li>
                <li><strong>Implementation Walkthrough</strong>: Line-by-line explanation of the code</li>
                <li><strong>Practical Examples</strong>: Multiple use cases from different domains</li>
                <li><strong>Comparison Tables</strong>: Side-by-side comparisons with related algorithms</li>
                <li><strong>When to Use</strong>: Clear guidance on algorithm selection criteria</li>
            </ul>

            <h3>2. üíª Production-Quality Code</h3>
            <p>
                All implementations follow best practices:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Clean Architecture Pattern</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">class</span> <span class="function">AlgorithmName</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, hyperparameter1=default1, ...):
        <span class="string">"""Initialize with hyperparameters"""</span>
        
    <span class="keyword">def</span> <span class="function">fit</span>(self, X, y):
        <span class="string">"""Train the model on training data"""</span>
        
    <span class="keyword">def</span> <span class="function">predict</span>(self, X):
        <span class="string">"""Make predictions on new data"""</span>
        
    <span class="keyword">def</span> <span class="function">score</span>(self, X, y):
        <span class="string">"""Evaluate model performance"""</span>
        
    <span class="keyword">def</span> <span class="function">get_coefficients</span>(self):
        <span class="string">"""Get learned parameters"""</span></code></pre>
            </div>

            <p>
                Features include:
            </p>
            <ul>
                <li>Clean object-oriented design with well-defined interfaces</li>
                <li>Detailed docstrings for every method</li>
                <li>Type hints for parameters and return values</li>
                <li>Robust error handling and edge case management</li>
                <li>Scikit-learn-like API for familiarity</li>
                <li>PEP 8 compliance and Python best practices</li>
            </ul>

            <h3>3. üßÆ Mathematical Rigor</h3>
            <p>
                Understanding the math is critical. Each algorithm includes:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Linear Regression Normal Equation</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="comment"># Normal Equation: Œ∏ = (X^T X)^(-1) X^T y</span>
<span class="keyword">def</span> <span class="function">fit</span>(self, X, y):
    <span class="comment"># Add bias term (column of ones)</span>
    X_with_bias = np.c_[np.ones((X.shape[<span class="number">0</span>], <span class="number">1</span>)), X]
    
    <span class="comment"># Calculate coefficients using Normal Equation</span>
    <span class="comment"># Inverts (X^T X) and multiplies by X^T y</span>
    self.coefficients = np.linalg.inv(
        X_with_bias.T @ X_with_bias
    ) @ X_with_bias.T @ y
    
    <span class="keyword">return</span> self</code></pre>
            </div>

            <p>
                Mathematical coverage includes:
            </p>
            <ul>
                <li><strong>Formal Definitions</strong>: Precise mathematical notation</li>
                <li><strong>Derivations</strong>: Step-by-step derivation of key formulas</li>
                <li><strong>Gradient Calculations</strong>: Detailed breakdown of optimization steps</li>
                <li><strong>Loss Functions</strong>: Explanation of why specific loss functions are used</li>
                <li><strong>Complexity Analysis</strong>: Time and space complexity discussions</li>
            </ul>

            <h2>Implementation Example: Logistic Regression</h2>
            <p>
                Complete implementation demonstrating the gradient descent approach for binary classification:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Logistic Regression with Gradient Descent</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer
<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler

<span class="keyword">class</span> <span class="function">LogisticRegression</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, learning_rate=<span class="number">0.01</span>, iterations=<span class="number">1000</span>):
        self.learning_rate = learning_rate
        self.iterations = iterations
        self.coefficients = <span class="keyword">None</span>
        self.losses = []
    
    <span class="keyword">def</span> <span class="function">_sigmoid</span>(self, z):
        <span class="string">"""Sigmoid activation function"""</span>
        <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))
    
    <span class="keyword">def</span> <span class="function">fit</span>(self, X, y):
        <span class="string">"""Train using gradient descent"""</span>
        n_samples, n_features = X.shape
        
        <span class="comment"># Add bias term</span>
        X_with_bias = np.c_[np.ones((n_samples, <span class="number">1</span>)), X]
        
        <span class="comment"># Initialize coefficients</span>
        self.coefficients = np.zeros(n_features + <span class="number">1</span>)
        
        <span class="comment"># Gradient descent</span>
        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.iterations):
            <span class="comment"># Forward pass</span>
            y_pred = self._sigmoid(X_with_bias @ self.coefficients)
            
            <span class="comment"># Calculate loss (binary cross-entropy)</span>
            loss = -np.mean(
                y * np.log(y_pred + <span class="number">1e-15</span>) + 
                (<span class="number">1</span> - y) * np.log(<span class="number">1</span> - y_pred + <span class="number">1e-15</span>)
            )
            self.losses.append(loss)
            
            <span class="comment"># Calculate gradients</span>
            error = y_pred - y
            gradients = (<span class="number">1</span> / n_samples) * (X_with_bias.T @ error)
            
            <span class="comment"># Update coefficients</span>
            self.coefficients -= self.learning_rate * gradients
        
        <span class="keyword">return</span> self
    
    <span class="keyword">def</span> <span class="function">predict</span>(self, X):
        <span class="string">"""Make binary predictions"""</span>
        X_with_bias = np.c_[np.ones((X.shape[<span class="number">0</span>], <span class="number">1</span>)), X]
        probabilities = self._sigmoid(X_with_bias @ self.coefficients)
        <span class="keyword">return</span> (probabilities >= <span class="number">0.5</span>).astype(int)
    
    <span class="keyword">def</span> <span class="function">score</span>(self, X, y):
        <span class="string">"""Calculate accuracy"""</span>
        predictions = self.predict(X)
        <span class="keyword">return</span> np.mean(predictions == y)

<span class="comment"># Usage Example</span>
data = load_breast_cancer()
X, y = data.data, data.target

<span class="comment"># Split and standardize</span>
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>
)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

<span class="comment"># Train model</span>
model = LogisticRegression(learning_rate=<span class="number">0.1</span>, iterations=<span class="number">2000</span>)
model.fit(X_train, y_train)

<span class="comment"># Evaluate</span>
accuracy = model.score(X_test, y_test)
print(<span class="string">f"Accuracy: </span>{accuracy:<span class="number">.4</span>f}<span class="string">"</span>)  <span class="comment"># Output: ~0.96</span></code></pre>
            </div>

            <h2>Algorithm Progression</h2>
            <p>
                Algorithms are structured in progressive difficulty, building foundational concepts before advanced techniques:
            </p>

            <div style="background: var(--secondary-bg); padding: 2rem; border-radius: 10px; border: 1px solid var(--border-color); margin: 2rem 0;">
                <h3 style="margin-top: 0;">Week 1: Linear Models</h3>
                <ol>
                    <li><strong>Linear Regression</strong> (2 hours)<br>
                        <span style="color: var(--text-secondary);">Foundation of all ML ‚Ä¢ Normal Equation ‚Ä¢ Bias & Slope</span>
                    </li>
                    <li><strong>Multiple Regression</strong> (2 hours)<br>
                        <span style="color: var(--text-secondary);">Multiple features ‚Ä¢ Matrix operations ‚Ä¢ Multicollinearity</span>
                    </li>
                </ol>
                
                <h3>Week 2: Regularization & Classification</h3>
                <ol start="3">
                    <li><strong>Ridge Regression</strong> (2-3 hours)<br>
                        <span style="color: var(--text-secondary);">Overfitting ‚Ä¢ L2 regularization ‚Ä¢ Hyperparameter tuning</span>
                    </li>
                    <li><strong>Logistic Regression</strong> (3 hours)<br>
                        <span style="color: var(--text-secondary);">Classification ‚Ä¢ Sigmoid function ‚Ä¢ Gradient descent ‚Ä¢ Binary cross-entropy</span>
                    </li>
                </ol>
            </div>

            <h3>Usage Recommendations</h3>
            <ul>
                <li>Review documentation files before examining implementation code</li>
                <li>Execute provided examples with real datasets to verify functionality</li>
                <li>Experiment with hyperparameter modifications to observe behavior changes</li>
                <li>Compare outputs with scikit-learn implementations for validation</li>
                <li>Utilize as reference material for interview preparation</li>
                <li>Extend implementations for specific use cases or research</li>
            </ul>

            <h2>Technical Deep-Dive</h2>
            
            <h3>Ridge Regression Implementation</h3>
            <p>
                Ridge regression implementation demonstrates L2 regularization through the modified Normal Equation:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Ridge Regression with Regularization</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="comment"># Regularized Normal Equation: Œ∏ = (X^T X + ŒªI)^(-1) X^T y</span>
<span class="keyword">def</span> <span class="function">fit</span>(self, X, y):
    X_with_bias = np.c_[np.ones((X.shape[<span class="number">0</span>], <span class="number">1</span>)), X]
    
    <span class="comment"># Create identity matrix (don't penalize bias term)</span>
    identity = np.eye(X_with_bias.shape[<span class="number">1</span>])
    identity[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">0</span>  <span class="comment"># Don't regularize intercept</span>
    
    <span class="comment"># Add regularization term (ŒªI)</span>
    regularization_term = self.alpha * identity
    
    <span class="comment"># Solve regularized Normal Equation</span>
    self.coefficients = np.linalg.inv(
        X_with_bias.T @ X_with_bias + regularization_term
    ) @ X_with_bias.T @ y
    
    <span class="keyword">return</span> self</code></pre>
            </div>

            <h3>Performance Characteristics</h3>
            <div class="table-container">
                <table class="content-table">
                    <thead>
                        <tr>
                            <th>Algorithm</th>
                            <th>Training Time</th>
                            <th>Prediction Time</th>
                            <th>Memory Usage</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Linear Regression</td>
                            <td>O(n¬≥)</td>
                            <td>O(n)</td>
                            <td>O(n¬≤)</td>
                        </tr>
                        <tr>
                            <td>Multiple Regression</td>
                            <td>O(n¬≥)</td>
                            <td>O(n)</td>
                            <td>O(n¬≤)</td>
                        </tr>
                        <tr>
                            <td>Ridge Regression</td>
                            <td>O(n¬≥)</td>
                            <td>O(n)</td>
                            <td>O(n¬≤)</td>
                        </tr>
                        <tr>
                            <td>Logistic Regression</td>
                            <td>O(i¬∑n¬≤)</td>
                            <td>O(n)</td>
                            <td>O(n)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p style="color: var(--text-secondary); font-style: italic; text-align: center;">
                where n = number of samples, i = iterations
            </p>

            <h2>Installation & Setup</h2>
            <p>
                The project requires Python 3.7+ and NumPy. Setup process:
            </p>

            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Bash - Installation & Setup</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="comment"># 1. Clone the repository</span>
git clone https://github.com/inboxpraveen/ML-Algorithms-from-scratch.git
cd ML-Algorithms-from-scratch

<span class="comment"># 2. Install dependencies</span>
pip install numpy

<span class="comment"># 3. Install optional dependencies for examples</span>
pip install matplotlib scikit-learn pandas jupyter

<span class="comment"># 4. Run an example</span>
python <span class="string">"1. Linear Regression/_1_linear_regressions.py"</span></code></pre>
            </div>

            <h3>Quick Start Example</h3>
            <div class="code-block">
                <div class="code-header">
                    <span class="code-language">Python - Quick Start</span>
                    <button class="copy-button">Copy</button>
                </div>
                <pre><code><span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> sys
sys.path.append(<span class="string">'1. Linear Regression'</span>)
<span class="keyword">from</span> _1_linear_regressions <span class="keyword">import</span> LinearRegression

<span class="comment"># Create sample data (years of experience vs salary)</span>
X_train = np.array([<span class="number">1, 2, 3, 4, 5, 6, 7, 8, 9, 10</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)
y_train = np.array([<span class="number">30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000</span>])

<span class="comment"># Create and train model</span>
model = LinearRegression()
model.fit(X_train, y_train)

<span class="comment"># Make predictions</span>
X_test = np.array([<span class="number">11, 12, 15</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)
predictions = model.predict(X_test)

<span class="comment"># Evaluate</span>
r2_score = model.score(X_train, y_train)
print(<span class="string">f"R¬≤ Score: </span>{r2_score:<span class="number">.4</span>f}<span class="string">"</span>)
print(<span class="string">f"Predictions: </span>{predictions}<span class="string">"</span>)

<span class="comment"># Get learned coefficients</span>
coeffs = model.get_coefficients()
print(<span class="string">f"Equation: y = </span>{coeffs[<span class="string">'intercept'</span>]:<span class="number">.2</span>f} <span class="string">+ </span>{coeffs[<span class="string">'slope'</span>]:<span class="number">.2</span>f}<span class="string">x"</span>)</code></pre>
            </div>

            <h2>Use Cases</h2>
            
            <h3>Academic Applications</h3>
            <ul>
                <li><strong>Coursework Reference:</strong> Complete implementations for ML course assignments</li>
                <li><strong>Exam Preparation:</strong> Comprehensive coverage of fundamental ML concepts</li>
                <li><strong>Research Foundation:</strong> Base implementations for custom algorithm development</li>
                <li><strong>Teaching Material:</strong> Structured content for ML education</li>
            </ul>

            <h3>Professional Development</h3>
            <p>
                The repository addresses common technical interview requirements:
            </p>

            <div style="background: var(--secondary-bg); padding: 1.5rem; border-radius: 10px; border: 1px solid var(--border-color); margin: 1rem 0;">
                <h4 style="margin-top: 0; color: var(--accent-color);">Technical Questions:</h4>
                <ul style="margin-bottom: 0;">
                    <li>"Implement linear regression from scratch"</li>
                    <li>"Explain the difference between L1 and L2 regularization"</li>
                    <li>"How does gradient descent work?"</li>
                    <li>"What is the difference between classification and regression?"</li>
                    <li>"When would you use Ridge vs Lasso regression?"</li>
                </ul>
            </div>

            <div style="background: var(--secondary-bg); padding: 1.5rem; border-radius: 10px; border: 1px solid var(--border-color); margin: 1rem 0;">
                <h4 style="margin-top: 0; color: var(--accent-color);">Conceptual Questions:</h4>
                <ul style="margin-bottom: 0;">
                    <li>"What is overfitting and how do you prevent it?"</li>
                    <li>"Explain the bias-variance tradeoff"</li>
                    <li>"How do you choose between different ML algorithms?"</li>
                    <li>"What is the intuition behind logistic regression?"</li>
                </ul>
            </div>

            <h2>Design Philosophy</h2>
            
            <h3>Educational Clarity</h3>
            <p>
                Code prioritizes readability and understanding over computational optimization:
            </p>
            <ul>
                <li>Readable and self-documenting</li>
                <li>Conceptually clear over computationally optimal</li>
                <li>Easy to modify and experiment with</li>
                <li>Directly traceable to mathematical formulas</li>
            </ul>

            <h3>Consistent Interface Design</h3>
            <p>
                All algorithms follow the same API pattern, inspired by scikit-learn:
            </p>
            <ul>
                <li><code>__init__()</code>: Set hyperparameters</li>
                <li><code>fit(X, y)</code>: Train the model</li>
                <li><code>predict(X)</code>: Make predictions</li>
                <li><code>score(X, y)</code>: Evaluate performance</li>
                <li><code>get_coefficients()</code>: Inspect learned parameters</li>
            </ul>

            <h3>Documentation Standards</h3>
            <p>
                The project maintains a <strong>2.3:1 documentation-to-code ratio</strong>, ensuring comprehensive coverage:
            </p>
            <ul>
                <li>Every concept is explained multiple times in different ways</li>
                <li>Mathematical formulas are broken down step-by-step</li>
                <li>Real-world analogies make abstract concepts concrete</li>
                <li>Multiple examples show different use cases</li>
            </ul>

            <h2>Project Roadmap</h2>
            <div style="background: var(--secondary-bg); padding: 2rem; border-radius: 10px; border: 1px solid var(--border-color); margin: 2rem 0;">
                <h3 style="margin-top: 0;">Phase 1: Foundation ‚úÖ Complete (4/18)</h3>
                <p>‚úÖ Linear Regression<br>
                   ‚úÖ Multiple Regression<br>
                   ‚úÖ Ridge Regression<br>
                   ‚úÖ Logistic Regression</p>
                
                <h3>Phase 2: Classification üîÑ In Progress (0/4)</h3>
                <p>‚è≥ K-Nearest Neighbors (KNN)<br>
                   ‚è≥ Naive Bayes<br>
                   ‚è≥ Support Vector Machines (SVM)<br>
                   ‚è≥ Decision Trees</p>
                
                <h3>Phase 3: Ensemble Methods üìã Planned (0/4)</h3>
                <p>üìÖ Random Forests<br>
                   üìÖ AdaBoost<br>
                   üìÖ Gradient Boosting<br>
                   üìÖ XGBoost</p>
                
                <h3>Phase 4: Unsupervised Learning üìã Planned (0/4)</h3>
                <p>üìÖ k-Means Clustering<br>
                   üìÖ Hierarchical Clustering<br>
                   üìÖ Principal Component Analysis (PCA)<br>
                   üìÖ t-SNE</p>
            </div>

            <h2>Contributing</h2>
            <p>
                The project welcomes contributions across multiple areas. Contribution opportunities include:
            </p>

            <div class="table-container">
                <table class="content-table">
                    <thead>
                        <tr>
                            <th>Priority</th>
                            <th>Contribution Areas</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>High</strong></td>
                            <td>
                                ‚Ä¢ Implement remaining 14 algorithms<br>
                                ‚Ä¢ Add more examples to existing algorithms<br>
                                ‚Ä¢ Create visualization utilities<br>
                                ‚Ä¢ Add unit tests
                            </td>
                        </tr>
                        <tr>
                            <td><strong>Medium</strong></td>
                            <td>
                                ‚Ä¢ Bug fixes and improvements<br>
                                ‚Ä¢ Documentation enhancements<br>
                                ‚Ä¢ Translate documentation<br>
                                ‚Ä¢ Create video tutorials
                            </td>
                        </tr>
                        <tr>
                            <td><strong>Always Welcome</strong></td>
                            <td>
                                ‚Ä¢ Typo fixes<br>
                                ‚Ä¢ Grammar improvements<br>
                                ‚Ä¢ Better explanations<br>
                                ‚Ä¢ More examples
                            </td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h2>Project Impact</h2>
            <p>
                This repository provides foundational understanding of machine learning algorithms through complete, 
                well-documented implementations. The project serves as both a learning resource and reference material 
                for algorithm internals, supporting students, researchers, and professionals in developing deeper ML expertise.
            </p>

            <h3>Getting Started</h3>
            <ol>
                <li>Clone the repository from GitHub</li>
                <li>Review documentation for Linear Regression as the foundation</li>
                <li>Progress through algorithms in numbered order</li>
                <li>Execute provided examples with included datasets</li>
                <li>Modify implementations for specific use cases</li>
                <li>Contribute improvements or additional algorithms</li>
            </ol>

            <div style="margin-top: 3rem; padding: 2rem; background: var(--secondary-bg); border-radius: 15px; border: 1px solid var(--border-color);">
                <h3 style="margin-top: 0;">Resources & Links</h3>
                <ul style="margin-bottom: 2rem;">
                    <li><a href="https://github.com/inboxpraveen/ML-Algorithms-from-scratch" style="color: var(--accent-color);" target="_blank">üîó GitHub Repository</a></li>
                    <li><a href="https://github.com/inboxpraveen/ML-Algorithms-from-scratch#readme" style="color: var(--accent-color);" target="_blank">üìÑ Full Project README</a></li>
                    <li><a href="https://numpy.org/doc/" style="color: var(--accent-color);" target="_blank">üìö NumPy Documentation</a></li>
                    <li><a href="https://scikit-learn.org/" style="color: var(--accent-color);" target="_blank">üî¨ Scikit-learn Documentation</a></li>
                </ul>
                
                <h4>Tags:</h4>
                <div style="display: flex; gap: 0.5rem; flex-wrap: wrap; margin-top: 1rem;">
                    <span class="tech-tag">#MachineLearning</span>
                    <span class="tech-tag">#Python</span>
                    <span class="tech-tag">#NumPy</span>
                    <span class="tech-tag">#FromScratch</span>
                    <span class="tech-tag">#Education</span>
                    <span class="tech-tag">#MLAlgorithms</span>
                    <span class="tech-tag">#DataScience</span>
                    <span class="tech-tag">#LinearRegression</span>
                    <span class="tech-tag">#LogisticRegression</span>
                    <span class="tech-tag">#GradientDescent</span>
                </div>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer style="margin-top: 4rem;">
        <div class="container">
            <p>&copy; <span id="copyright-year"></span> Praveen Kumar. Built with passion for AI & open source community.</p>
        </div>
    </footer>

    <script>
        // Mobile menu functionality
        const mobileMenu = document.getElementById('mobileMenu');
        const navLinks = document.getElementById('navLinks');

        mobileMenu.addEventListener('click', () => {
            navLinks.classList.toggle('active');
        });

        // Copy button functionality
        document.addEventListener('click', function(e) {
            if (e.target.classList.contains('copy-button')) {
                const codeBlock = e.target.closest('.code-block');
                const code = codeBlock.querySelector('pre').textContent;
                
                navigator.clipboard.writeText(code).then(() => {
                    e.target.textContent = 'Copied!';
                    setTimeout(() => {
                        e.target.textContent = 'Copy';
                    }, 2000);
                });
            }
        });

        // Navbar background on scroll
        window.addEventListener('scroll', () => {
            const nav = document.querySelector('nav');
            if (window.scrollY > 100) {
                nav.style.background = 'rgba(10, 10, 10, 0.98)';
            } else {
                nav.style.background = 'rgba(10, 10, 10, 0.95)';
            }
        });

        // Update copyright year dynamically
        window.addEventListener('load', function() {
            const yearElement = document.getElementById('copyright-year');
            if (yearElement) {
                yearElement.textContent = new Date().getFullYear();
            }
        });
    </script>
</body>
</html>
